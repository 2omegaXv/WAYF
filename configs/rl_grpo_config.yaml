# Configuration for RL Training (GRPO)

# Base model and SFT checkpoint
model:
  base_name: "Qwen/Qwen2-7B-Instruct"
  sft_checkpoint: "models/sft"

# Reward model
reward:
  classifier_path: "models/classifier/best_model.pt"
  label_map_path: "models/classifier/label_map.json"
  
  # Reward weights
  w_cls: 1.0      # Classifier reward weight
  w_qual: 0.5     # Quality reward weight
  w_kl: 0.1       # KL penalty weight

# GRPO-specific parameters
grpo:
  num_generations: 4  # Number of generations per prompt

# Training parameters
training:
  batch_size: 4
  gradient_accumulation_steps: 4
  epochs: 3
  learning_rate: 1e-5
  seed: 42
  fp16: true

# Instruction template
instruction:
  template: "Translate the following {src_lang} text to Chinese:\n\n{src_text}"

# Paths
paths:
  train_file: "data/rl/pool_b.jsonl"
  output_dir: "models/rl_grpo"

# Hyperparameter sweep for w_cls
sweep:
  enabled: false
  w_cls_values: [0.5, 1.0, 1.5, 2.0]
