# Configuration for RL Training (GRPO)

# Base model and SFT checkpoint
model:
  base_name: "models/hf_backbones/Qwen3-4B-Instruct-2507"

# Reward model
reward:
  classifier_backbone: "/root/WAYF/models/hf_backbones/chinese-roberta-wwm-ext"
  classifier_path: "models/classifier/Qwen_full/best_model.pt"
  label_map_path: "models/classifier/Qwen_full/label_map.json"
  
  # Reward weights
  w_cls: 1.0      # Classifier reward weight
  w_kl: 0.1       # KL penalty weight

# GRPO-specific parameters
grpo:
  num_generations: 4  # Number of generations per prompt

# Training parameters
training:
  batch_size: 16
  gradient_accumulation_steps: 1
  epochs: 3
  learning_rate: 1e-5
  seed: 42
  fp16: true

# Instruction template
instruction:
  template: "Translate the following {src_lang} text to Chinese:\n\n{src_text}"

# Paths
paths:
  train_file: "data/rl/grpo_train.jsonl"
  output_dir: "models/rl_grpo"

wandb:
  project: "WAYF-RL"
  name: "grpo-qwen3-4b-lora"
  mode: "online"